{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \n",
    "    def __init__(self, network_structure):\n",
    "        #network_structure -> [2,3,4...5], each element represents the number of nodes\n",
    "        # in the layer, and the length of the array is the number of layers\n",
    "        self.number_of_layers = len(network_structure)\n",
    "        self.biases = []\n",
    "        self.weights = []\n",
    "        #initial biases and weights are all zeros\n",
    "        for num_of_nodes in network_structure[1:]:\n",
    "            layer_bias = np.zeros((num_of_nodes,1))\n",
    "            self.biases.append(layer_bias)\n",
    "        self.biases = np.array(self.biases)\n",
    "        \n",
    "        for previous_layer_num_nodes, current_layer_num_nodes in zip(network_structure[:-1],network_structure[1:]):\n",
    "            layer_weights = np.zeros((current_layer_num_nodes, previous_layer_num_nodes))\n",
    "            self.weights.append(layer_weights)\n",
    "        self.weights = np.array(self.weights)\n",
    "        \n",
    "    def gradient_descent(self, original_value, learning_rate, gradients):\n",
    "        #this function returns the new value after gradient descent\n",
    "        output = original_value\n",
    "        for index, gradient in enumerate(gradients):\n",
    "            print(\"Gradient descent index: {0}\").format(index)\n",
    "            output = output - learning_rate*gradient/self.number_of_training_examples\n",
    "        return \n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def sigmoid_prime(self, z):\n",
    "        return self.sigmoid(z)*(1-self.sigmoid(z))\n",
    "    \n",
    "    def layer_output(self, input_matrix, layer):\n",
    "        layer_weights = self.weights[layer-1]\n",
    "        layer_biases = self.biases[layer-1]\n",
    "        z = (np.dot(layer_weights, input_matrix.transpose()) + layer_biases).transpose()\n",
    "        print(\"Layer output Input shape: {0}\").format(input_matrix.shape)\n",
    "        print(\"Layer Output Input Transpose shape: {0}\").format(input_matrix.transpose().shape)\n",
    "        print(\"Layer Output Weights shape: {0}\").format(layer_weights.shape)\n",
    "        print(\"Layer Output Z shape: {0}\").format(z.shape)\n",
    "        output_matrix = self.sigmoid(z)\n",
    "        print(\"Layer Output Output shape {0}\").format(output_matrix.shape)\n",
    "        return (np.array(z), np.array(output_matrix))\n",
    "    \n",
    "    def cost_function_derivative(self, predicted_output, output_matrix):\n",
    "        return (predicted_output - output_matrix)\n",
    "    \n",
    "    def feed_forward(self, input_matrix):\n",
    "        current_input = input_matrix\n",
    "        zs = []\n",
    "        activations = [current_input]\n",
    "        print(\"Feed forward Initial Activations: {0}\").format(activations)\n",
    "        #Here we have feeded the input matrix into the network, computed all the activation values\n",
    "        for layer in xrange(1, self.number_of_layers):\n",
    "            (z, output) = self.layer_output(current_input, layer)\n",
    "            print(\"Feed forward Output shape: {0}\").format(output.shape)\n",
    "            activations.append(output)\n",
    "            print(\"Feed forward New activation: {0}\").format(output)\n",
    "            print(\"Feed forward Activations: {0}\").format(activations)\n",
    "            zs.append(z)\n",
    "            current_input = output\n",
    "            \n",
    "        #print(\"Feed forward Activations shape: {0}\").format(activations.shape)\n",
    "        return (zs, activations)\n",
    "    \n",
    "    def back_propagation(self, input_matrix, output_matrix, zs, activations):\n",
    "        #try np.zeros(self.biases.shape)\n",
    "        delta_b = [np.zeros(self.biases.shape) for bias in self.biases]\n",
    "        #try np.zeros(self.weights.shape)\n",
    "        delta_w = [np.zeros(self.weights.shape) for weights in self.weights]\n",
    "        delta = self.cost_function_derivative(activations[-1], output_matrix) * self.sigmoid_prime(zs[-1])\n",
    "        \n",
    "        for l in xrange(2,self.number_of_layers):\n",
    "            #l represents the layers when we are coming back from output to input\n",
    "            z = zs[-l]\n",
    "            #weights(l-1) -> weights of (l-1) layer\n",
    "            weights_l_1 = self.weights[-l+1]\n",
    "            delta_l_1 = delta[-l+1]\n",
    "            sigmoid_prime_z = self.sigmoid_prime(z)\n",
    "            delta = np.dot(weights_l_1.transpose(), delta_l_1)*sigmoid_prime_z\n",
    "            delta_b[-l] = delta\n",
    "            #print(\"Back Propagation Activations shape: {0}, Delta Shape: {1}\").format(activations.transpose().shape, delta.shape)\n",
    "            delta_w[-l] = np.dot(activations[-l-1].transpose(), delta)\n",
    "        \n",
    "        #print(\"Back Propagation Shape DW: {0}\").format(delta_w.shape)\n",
    "        return (delta_b,delta_w)\n",
    "    \n",
    "    def fit(self, train_data, learning_rate, epochs, mini_batch_size, test_data):\n",
    "        \n",
    "        self.epochs = epochs\n",
    "        feature_train_matrix = train_data[0]\n",
    "        label_train_matrix = train_data[1]  \n",
    "        feature_test_matrix = test_data[0]\n",
    "        label_test_matrix = test_data[1]\n",
    "        self.number_of_training_examples = len(feature_train_matrix)\n",
    "        self.epochs = epochs\n",
    "            \n",
    "        for epoch in xrange(self.epochs):\n",
    "            mini_batch_inputs = [feature_train_matrix[k:k+mini_batch_size] for k in xrange(0,len(feature_train_matrix),mini_batch_size)]\n",
    "            mini_batch_outputs = [label_train_matrix[k:k+mini_batch_size] for k in xrange(0, len(label_train_matrix), mini_batch_size)]\n",
    "            \n",
    "            for mini_batch_input, mini_batch_output in zip(mini_batch_inputs, mini_batch_outputs):\n",
    "                zs, activations = self.feed_forward(mini_batch_input)\n",
    "                delta_b, delta_w = self.back_propagation(mini_batch_input, mini_batch_output, zs, activations)\n",
    "                self.biases = [self.gradient_descent(bias, learning_rate, db) for db, bias in zip(delta_b, self.biases)]\n",
    "                self.weights = [self.gradient_descent(weight, learning_rate, dw) for dw, weight in zip(delta_w, self.weights)]\n",
    "            \n",
    "            correctly_predicted = 0\n",
    "            for index, o in enumerate(label_test_matrix):\n",
    "                i = feature_test_matrix[index]\n",
    "                predicted_output = self.feed_forward(i)\n",
    "                predicted = True\n",
    "                for p,a in zip(predicted_output, o):\n",
    "                    if p != a:\n",
    "                        predicted = False\n",
    "                if predicted == True:\n",
    "                    correctly_predicted = correctly_predicted + 1\n",
    "                print(\"Epoch {0}: {1}/{2}\").format(epoch, correctly_predicted,len(feature_train_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = mnist[:40000]\n",
    "test_data = mnist[40000:42000]\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "39995      0       0       0       0       0       0       0       0       0   \n",
       "39996      3       0       0       0       0       0       0       0       0   \n",
       "39997      0       0       0       0       0       0       0       0       0   \n",
       "39998      0       0       0       0       0       0       0       0       0   \n",
       "39999      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "39995       0    ...            0         0         0         0         0   \n",
       "39996       0    ...            0         0         0         0         0   \n",
       "39997       0    ...            0         0         0         0         0   \n",
       "39998       0    ...            0         0         0         0         0   \n",
       "39999       0    ...            0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "39995         0         0         0         0         0  \n",
       "39996         0         0         0         0         0  \n",
       "39997         0         0         0         0         0  \n",
       "39998         0         0         0         0         0  \n",
       "39999         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_one_hot(input_dataframe):\n",
    "    labels = input_dataframe.iloc[:,:1].values.ravel()\n",
    "    unique_values = np.unique(labels)\n",
    "    output = []\n",
    "    for label in labels:\n",
    "        one_hot_vector = np.zeros((len(unique_values),1))\n",
    "        one_hot_vector[label] = 1\n",
    "        output.append(one_hot_vector)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_train_features = train_data.iloc[:,1:].values\n",
    "nn_train_labels = convert_to_one_hot(train_data)\n",
    "nn_test_features = test_data.iloc[:,1:].values\n",
    "nn_test_labels = convert_to_one_hot(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_train = (nn_train_features, [label.ravel() for label in nn_train_labels])\n",
    "nn_test = (nn_test_features, [label.ravel() for label in nn_test_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_train_labels[0].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feed forward Initial Activations: [array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])]\n",
      "Layer output Input shape: (200, 784)\n",
      "Layer Output Input Transpose shape: (784, 200)\n",
      "Layer Output Weights shape: (30, 784)\n",
      "Layer Output Z shape: (200, 30)\n",
      "Layer Output Output shape (200, 30)\n",
      "Feed forward Output shape: (200, 30)\n",
      "Feed forward New activation: [[ 0.5  0.5  0.5 ...,  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...,  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...,  0.5  0.5  0.5]\n",
      " ..., \n",
      " [ 0.5  0.5  0.5 ...,  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...,  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...,  0.5  0.5  0.5]]\n",
      "Feed forward Activations: [array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]]), array([[ 0.5,  0.5,  0.5, ...,  0.5,  0.5,  0.5],\n",
      "       [ 0.5,  0.5,  0.5, ...,  0.5,  0.5,  0.5],\n",
      "       [ 0.5,  0.5,  0.5, ...,  0.5,  0.5,  0.5],\n",
      "       ..., \n",
      "       [ 0.5,  0.5,  0.5, ...,  0.5,  0.5,  0.5],\n",
      "       [ 0.5,  0.5,  0.5, ...,  0.5,  0.5,  0.5],\n",
      "       [ 0.5,  0.5,  0.5, ...,  0.5,  0.5,  0.5]])]\n",
      "Layer output Input shape: (200, 30)\n",
      "Layer Output Input Transpose shape: (30, 200)\n",
      "Layer Output Weights shape: (10, 30)\n",
      "Layer Output Z shape: (200, 10)\n",
      "Layer Output Output shape (200, 10)\n",
      "Feed forward Output shape: (200, 10)\n",
      "Feed forward New activation: [[ 0.5  0.5  0.5 ...,  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...,  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...,  0.5  0.5  0.5]\n",
      " ..., \n",
      " [ 0.5  0.5  0.5 ...,  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...,  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...,  0.5  0.5  0.5]]\n",
      "Feed forward Activations: [array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]]), array([[ 0.5,  0.5,  0.5, ...,  0.5,  0.5,  0.5],\n",
      "       [ 0.5,  0.5,  0.5, ...,  0.5,  0.5,  0.5],\n",
      "       [ 0.5,  0.5,  0.5, ...,  0.5,  0.5,  0.5],\n",
      "       ..., \n",
      "       [ 0.5,  0.5,  0.5, ...,  0.5,  0.5,  0.5],\n",
      "       [ 0.5,  0.5,  0.5, ...,  0.5,  0.5,  0.5],\n",
      "       [ 0.5,  0.5,  0.5, ...,  0.5,  0.5,  0.5]]), array([[ 0.5,  0.5,  0.5, ...,  0.5,  0.5,  0.5],\n",
      "       [ 0.5,  0.5,  0.5, ...,  0.5,  0.5,  0.5],\n",
      "       [ 0.5,  0.5,  0.5, ...,  0.5,  0.5,  0.5],\n",
      "       ..., \n",
      "       [ 0.5,  0.5,  0.5, ...,  0.5,  0.5,  0.5],\n",
      "       [ 0.5,  0.5,  0.5, ...,  0.5,  0.5,  0.5],\n",
      "       [ 0.5,  0.5,  0.5, ...,  0.5,  0.5,  0.5]])]\n",
      "Gradient descent index: 0\n",
      "Gradient descent index: 1\n",
      "Gradient descent index: 2\n",
      "Gradient descent index: 3\n",
      "Gradient descent index: 4\n",
      "Gradient descent index: 5\n",
      "Gradient descent index: 6\n",
      "Gradient descent index: 7\n",
      "Gradient descent index: 8\n",
      "Gradient descent index: 9\n",
      "Gradient descent index: 10\n",
      "Gradient descent index: 11\n",
      "Gradient descent index: 12\n",
      "Gradient descent index: 13\n",
      "Gradient descent index: 14\n",
      "Gradient descent index: 15\n",
      "Gradient descent index: 16\n",
      "Gradient descent index: 17\n",
      "Gradient descent index: 18\n",
      "Gradient descent index: 19\n",
      "Gradient descent index: 20\n",
      "Gradient descent index: 21\n",
      "Gradient descent index: 22\n",
      "Gradient descent index: 23\n",
      "Gradient descent index: 24\n",
      "Gradient descent index: 25\n",
      "Gradient descent index: 26\n",
      "Gradient descent index: 27\n",
      "Gradient descent index: 28\n",
      "Gradient descent index: 29\n",
      "Gradient descent index: 30\n",
      "Gradient descent index: 31\n",
      "Gradient descent index: 32\n",
      "Gradient descent index: 33\n",
      "Gradient descent index: 34\n",
      "Gradient descent index: 35\n",
      "Gradient descent index: 36\n",
      "Gradient descent index: 37\n",
      "Gradient descent index: 38\n",
      "Gradient descent index: 39\n",
      "Gradient descent index: 40\n",
      "Gradient descent index: 41\n",
      "Gradient descent index: 42\n",
      "Gradient descent index: 43\n",
      "Gradient descent index: 44\n",
      "Gradient descent index: 45\n",
      "Gradient descent index: 46\n",
      "Gradient descent index: 47\n",
      "Gradient descent index: 48\n",
      "Gradient descent index: 49\n",
      "Gradient descent index: 50\n",
      "Gradient descent index: 51\n",
      "Gradient descent index: 52\n",
      "Gradient descent index: 53\n",
      "Gradient descent index: 54\n",
      "Gradient descent index: 55\n",
      "Gradient descent index: 56\n",
      "Gradient descent index: 57\n",
      "Gradient descent index: 58\n",
      "Gradient descent index: 59\n",
      "Gradient descent index: 60\n",
      "Gradient descent index: 61\n",
      "Gradient descent index: 62\n",
      "Gradient descent index: 63\n",
      "Gradient descent index: 64\n",
      "Gradient descent index: 65\n",
      "Gradient descent index: 66\n",
      "Gradient descent index: 67\n",
      "Gradient descent index: 68\n",
      "Gradient descent index: 69\n",
      "Gradient descent index: 70\n",
      "Gradient descent index: 71\n",
      "Gradient descent index: 72\n",
      "Gradient descent index: 73\n",
      "Gradient descent index: 74\n",
      "Gradient descent index: 75\n",
      "Gradient descent index: 76\n",
      "Gradient descent index: 77\n",
      "Gradient descent index: 78\n",
      "Gradient descent index: 79\n",
      "Gradient descent index: 80\n",
      "Gradient descent index: 81\n",
      "Gradient descent index: 82\n",
      "Gradient descent index: 83\n",
      "Gradient descent index: 84\n",
      "Gradient descent index: 85\n",
      "Gradient descent index: 86\n",
      "Gradient descent index: 87\n",
      "Gradient descent index: 88\n",
      "Gradient descent index: 89\n",
      "Gradient descent index: 90\n",
      "Gradient descent index: 91\n",
      "Gradient descent index: 92\n",
      "Gradient descent index: 93\n",
      "Gradient descent index: 94\n",
      "Gradient descent index: 95\n",
      "Gradient descent index: 96\n",
      "Gradient descent index: 97\n",
      "Gradient descent index: 98\n",
      "Gradient descent index: 99\n",
      "Gradient descent index: 100\n",
      "Gradient descent index: 101\n",
      "Gradient descent index: 102\n",
      "Gradient descent index: 103\n",
      "Gradient descent index: 104\n",
      "Gradient descent index: 105\n",
      "Gradient descent index: 106\n",
      "Gradient descent index: 107\n",
      "Gradient descent index: 108\n",
      "Gradient descent index: 109\n",
      "Gradient descent index: 110\n",
      "Gradient descent index: 111\n",
      "Gradient descent index: 112\n",
      "Gradient descent index: 113\n",
      "Gradient descent index: 114\n",
      "Gradient descent index: 115\n",
      "Gradient descent index: 116\n",
      "Gradient descent index: 117\n",
      "Gradient descent index: 118\n",
      "Gradient descent index: 119\n",
      "Gradient descent index: 120\n",
      "Gradient descent index: 121\n",
      "Gradient descent index: 122\n",
      "Gradient descent index: 123\n",
      "Gradient descent index: 124\n",
      "Gradient descent index: 125\n",
      "Gradient descent index: 126\n",
      "Gradient descent index: 127\n",
      "Gradient descent index: 128\n",
      "Gradient descent index: 129\n",
      "Gradient descent index: 130\n",
      "Gradient descent index: 131\n",
      "Gradient descent index: 132\n",
      "Gradient descent index: 133\n",
      "Gradient descent index: 134\n",
      "Gradient descent index: 135\n",
      "Gradient descent index: 136\n",
      "Gradient descent index: 137\n",
      "Gradient descent index: 138\n",
      "Gradient descent index: 139\n",
      "Gradient descent index: 140\n",
      "Gradient descent index: 141\n",
      "Gradient descent index: 142\n",
      "Gradient descent index: 143\n",
      "Gradient descent index: 144\n",
      "Gradient descent index: 145\n",
      "Gradient descent index: 146\n",
      "Gradient descent index: 147\n",
      "Gradient descent index: 148\n",
      "Gradient descent index: 149\n",
      "Gradient descent index: 150\n",
      "Gradient descent index: 151\n",
      "Gradient descent index: 152\n",
      "Gradient descent index: 153\n",
      "Gradient descent index: 154\n",
      "Gradient descent index: 155\n",
      "Gradient descent index: 156\n",
      "Gradient descent index: 157\n",
      "Gradient descent index: 158\n",
      "Gradient descent index: 159\n",
      "Gradient descent index: 160\n",
      "Gradient descent index: 161\n",
      "Gradient descent index: 162\n",
      "Gradient descent index: 163\n",
      "Gradient descent index: 164\n",
      "Gradient descent index: 165\n",
      "Gradient descent index: 166\n",
      "Gradient descent index: 167\n",
      "Gradient descent index: 168\n",
      "Gradient descent index: 169\n",
      "Gradient descent index: 170\n",
      "Gradient descent index: 171\n",
      "Gradient descent index: 172\n",
      "Gradient descent index: 173\n",
      "Gradient descent index: 174\n",
      "Gradient descent index: 175\n",
      "Gradient descent index: 176\n",
      "Gradient descent index: 177\n",
      "Gradient descent index: 178\n",
      "Gradient descent index: 179\n",
      "Gradient descent index: 180\n",
      "Gradient descent index: 181\n",
      "Gradient descent index: 182\n",
      "Gradient descent index: 183\n",
      "Gradient descent index: 184\n",
      "Gradient descent index: 185\n",
      "Gradient descent index: 186\n",
      "Gradient descent index: 187\n",
      "Gradient descent index: 188\n",
      "Gradient descent index: 189\n",
      "Gradient descent index: 190\n",
      "Gradient descent index: 191\n",
      "Gradient descent index: 192\n",
      "Gradient descent index: 193\n",
      "Gradient descent index: 194\n",
      "Gradient descent index: 195\n",
      "Gradient descent index: 196\n",
      "Gradient descent index: 197\n",
      "Gradient descent index: 198\n",
      "Gradient descent index: 199\n",
      "Gradient descent index: 0\n",
      "Gradient descent index: 1\n",
      "Gradient descent index: 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (30,784) (30,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-285-15a5afb04fc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-284-7277f6412bf0>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, learning_rate, epochs, mini_batch_size, test_data)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mdelta_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mback_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mcorrectly_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-284-7277f6412bf0>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(self, original_value, learning_rate, gradients)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Gradient descent index: {0}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_training_examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (30,784) (30,) "
     ]
    }
   ],
   "source": [
    "network = Network([784,30,10])\n",
    "network.fit(nn_train, 0.01, 10, 200, nn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
