{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, network_structure):\n",
    "        #network_structure -> [2,3,4...5], each element represents the number of nodes\n",
    "        # in the layer, and the length of the array is the number of layers\n",
    "        self.input_matrix = input_matrix\n",
    "        self.output_matrix = output_matrix\n",
    "        self.number_of_training_examples = len(input_matrix)\n",
    "        self.number_of_layers = len(network_structure)\n",
    "        self.biases = []\n",
    "        self.weights = []\n",
    "        #initial biases and weights are all zeros\n",
    "        for num_of_nodes in network_structure[1:]:\n",
    "            layer_bias = np.zeros((num_of_nodes,1))\n",
    "            self.biases.append(layer_bias)\n",
    "        self.biases = np.array(self.biases)\n",
    "        \n",
    "        for previous_layer_num_nodes, current_layer_num_nodes in zip(network_structure[:-1],network_structure[1:]):\n",
    "            layer_weights = np.zeros((current_layer_num_nodes, previous_layer_num_nodes))\n",
    "            self.weights.append(layer_weights)\n",
    "        self.weights = np.array(self.weights)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "structure = np.array([2,4,3])\n",
    "network = Network(structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.]]),\n",
       "       array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.]])], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ array([[ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.]]),\n",
       "       array([[ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.]])], dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing! Things are going as planned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def gradient_descent(self, original_value, learning_rate, gradient):\n",
    "        #this function returns the new value after gradient descent\n",
    "        return (original_value - learning_rate*gradient/self.number_of_training_examples)\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def sigmoid_prime(self, z):\n",
    "        return sigmoid*(1-sigmoid)\n",
    "    \n",
    "    def layer_output(self, input_matrix, layer):\n",
    "        layer_weights = self.weights[layer-1]\n",
    "        layer_biases = self.biases[layer-1]\n",
    "        z = np.dot(layer_weights, input_matrix) + layer_biases\n",
    "        output_matrix = sigmoid(z)\n",
    "        return (np.array(z), np.array(output_matrix))\n",
    "    \n",
    "    def cost_function_derivative(self, predicted_output):\n",
    "        return (predicted_output - self.output_matrix)\n",
    "    \n",
    "    def feed_forward(self, input_matrix):\n",
    "        current_input = input_matrix\n",
    "        zs = []\n",
    "        activations = [current_input]\n",
    "        #Here we have feeded the input matrix into the network, computed all the activation values\n",
    "        for layer in xrange(1, self.number_of_layers):\n",
    "            (z, output) = layer_output(current_input, layer)\n",
    "            activations.append(output)\n",
    "            zs.append(z)\n",
    "            current_input = output\n",
    "            \n",
    "        return (zs, activations)\n",
    "    \n",
    "    def back_propagation(self, input_matrix, output_matrix, zs, activations):\n",
    "        #try np.zeros(self.biases.shape)\n",
    "        delta_b = [np.zeros(self.biases.shape) for bias in self.biases]\n",
    "        #try np.zeros(self.weights.shape)\n",
    "        delta_w = [np.zeros(self.weights.shape) for weights in self.weights]\n",
    "        delta = cost_function_derivative(activations[-1], output_matrix) * sigmoid_prime(zs[-1])\n",
    "        \n",
    "        for l in xrange(2,self.number_of_layers):\n",
    "            #l represents the layers when we are coming back from output to input\n",
    "            z = zs[-l]\n",
    "            #weights(l-1) -> weights of (l-1) layer\n",
    "            weights_l_1 = self.weights[-l+1]\n",
    "            delta_l_1 = delta[-l+1]\n",
    "            sigmoid_prime_z = sigmoid_prime(z)\n",
    "            delta = np.dot(weights_l_1.transpose(), delta_l_1)*sigmoid_prime_z\n",
    "            delta_b[-l] = delta\n",
    "            delta_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        \n",
    "        return (delta_b,delta_w)\n",
    "    \n",
    "    def fit(self, train_data, learning_rate, epochs, mini_batch_size, test_data):\n",
    "        input_train_matrix = []\n",
    "        output_train_matrix = []\n",
    "        self.epochs = epochs\n",
    "        for x, y in train_data:\n",
    "            input_matrix.append(x)\n",
    "            output_matrix.append(y)\n",
    "            \n",
    "        input_test_matrix = []\n",
    "        output_test_matrix = []\n",
    "        self.epochs = epochs\n",
    "        for x, y in test_data:\n",
    "            input_test_matrix.append(x)\n",
    "            output_test_matrix.append(y)\n",
    "            \n",
    "        for epoch in xrange(self.epochs):\n",
    "            mini_batch_inputs = [input_matrix[k:k+mini_batch_size] for k in xrange(0,len(input_matrix),mini_batch_size)]\n",
    "            mini_batch_outputs = [output_matrix[k:k+mini_batch_size] for k in xrange(0, len(output_matrix), mini_batch_size)]\n",
    "            \n",
    "            for mini_batch_input, mini_batch_output in zip(mini_batch_inputs, mini_batch_outputs):\n",
    "                zs, activations = feed_forward(mini_batch_input, mini_batch_output)\n",
    "                delta_b, delta_w = back_propagation(mini_batch_input, mini_batch_output, zs, activations)\n",
    "                self.biases = [gradient_descent(bias, learning_rate, db) for db, bias in zip(delta_b, self.biases)]\n",
    "                self.weights = [gradient_descent(weight, learning_rate, dw) for dw, weight in zip(delta_w, self.weights)]\n",
    "            \n",
    "            correctly_predicted = 0\n",
    "            for index, o in enumerate(output_test_matrix):\n",
    "                i = input_test_matrix[index]\n",
    "                predicted_output = self.feed_forward(i)\n",
    "                predicted = True\n",
    "                for p,a in zip(predicted_output, o):\n",
    "                    if p != a:\n",
    "                        predicted = False\n",
    "                if predicted == True:\n",
    "                    correctly_predicted = correctly_predicted + 1\n",
    "                print(\"Epoch {0}: {1}/{2}\").format(epoch, correctly_predicted,len(input_train_matrix))\n",
    "            \n",
    "        \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mnist_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '../data/mnist.pkl.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-5a7f65f4a3cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/neelbakshi/Documents/Machine Learning/MachineLearning/Neural Networks/mnist_loader.py\u001b[0m in \u001b[0;36mload_data_wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mturn\u001b[0m \u001b[0mout\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmost\u001b[0m \u001b[0mconvenient\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mour\u001b[0m \u001b[0mneural\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     code.\"\"\"\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mtr_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mtraining_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtr_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mtraining_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvectorized_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtr_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/neelbakshi/Documents/Machine Learning/MachineLearning/Neural Networks/mnist_loader.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mbelow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \"\"\"\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/mnist.pkl.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/neelbakshi/anaconda/lib/python2.7/gzip.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \"\"\"\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBufferedIOBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/neelbakshi/anaconda/lib/python2.7/gzip.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__builtin__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# Issue #13781: os.fdopen() creates a fileobj with a bogus name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '../data/mnist.pkl.gz'"
     ]
    }
   ],
   "source": [
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
