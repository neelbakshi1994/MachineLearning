{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to model a Network which will take an input as an array of number of nodes in each layer, and the length of the array being the number of layers (including the input nodes)\n",
    "It will calulate the weights and biases on its own. \n",
    "\n",
    "The convergence of the weights and biases will be done using **gradient descent**.\n",
    "\n",
    "The activation function that will be used is the **sigmoid function** and not the step function.\n",
    "\n",
    "We are following this tutorial:\n",
    "\n",
    "http://neuralnetworksanddeeplearning.com/chap1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network([2,3,4,2]) -> means that there are four layers, two hidden layers\n",
    "# 2 input nodes, 3 nodes in layer-1, 4 nodes in layer-2 and 2 output nodes\n",
    "class Network:\n",
    "    def __init__(self,structure):\n",
    "        self.structure = structure\n",
    "        self.number_of_layers = len(structure)\n",
    "        #biases and weights exist for all nodes except the input ones\n",
    "        #each bias is of the form 1 X 1\n",
    "        self.biases = [np.zeros(current_number_of_nodes,1) for current_number_of_nodes in structure[1:]]\n",
    "        #each weight is of the form 1 X previous_nodes\n",
    "        self.weights = [np.zeros(current_number_of_nodes, previous_number_of_nodes) for (current_number_of_nodes,previous_number_of_nodes) in zip(structure[1:],structure[:-1])]\n",
    "        \n",
    "    def sigmoid_func(z):\n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "    \n",
    "    #input is a matrix of the form previous_nodes X 1, whereas output is of the form current_nodes X 1\n",
    "    def output(self, input_matrix):\n",
    "        for (bias, weights) in zip(self.biases, self.weights):\n",
    "            input_matrix = np.dot(weights,input_matrix) + bias\n",
    "        return input_matrix\n",
    "        \n",
    "    def fit(self, training_data, num_of_epochs, mini_batch_size, learning_rate, test_data=None):\n",
    "        if test_data:\n",
    "            test_n = len(test_data)\n",
    "        training_n = len(training_data)\n",
    "        for epoch in xrange(0,num_of_epochs):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [training_data[k:k+mini_batch_size] for k in (0,n,mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.run_gradient_descent(mini_batch, learning_rate)\n",
    "                \n",
    "    def back_propagation(self, input, output):\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
