{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a technique used to find correlations between different features. Particularly useful when you want to remove a few features which you think do not bring much to the efficieny of your learning algorithm, or if you want to combine two or more features if you think they are representing the same thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic intuition behind PCA is that, we are trying to measure the data in terms of it's principal components:\n",
    "Prinicipal components are those structures of the data which hold the maximum information about it. In mathematical terms they are the dimensions in which you have the most variance.\n",
    "\n",
    "Let's say we have two features, which are plotted with feature-1 on x-axis and feature-2 on y-axis.\n",
    "We can find the principal component axis along which the shadow(mapping) of those data points will yield the maximum variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two quantities w.r.t to PCA which are very important, namely the **eigenvalues** and the **eigenvectors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eigenvalue** is the number telling you how much variance the data has\n",
    "**Eigenvector** is the direction in which this eigenvalue exists\n",
    "These two always exist in pairs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
